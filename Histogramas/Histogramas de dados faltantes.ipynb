{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b75cf1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbf36ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas = ['V0001', 'V0015', 'V0026', 'V0031', 'B001', 'C006', 'C00701', 'C00702', 'C00703', 'C009', 'C011', 'C012', 'D00901', 'D014', 'D015', 'E006011', 'E008', 'E010010', 'E01602', 'E01604',\n",
    "           'E017', 'E01802', 'E01804', 'E019', 'E027', 'F001011', 'F007011', 'F008011', 'VDF001', 'F016', 'G059', 'G060', 'G062', 'G032', 'I00102', 'I006', 'I004', 'I00401', 'I00402', 'I00403',\n",
    "           'I012', 'J001', 'J00101', 'J002', 'J00402', 'J00404', 'J007', 'J00801', 'J01101', 'J060', 'M001', 'M00302', 'M011011', 'M011021', 'M011051', 'M011071', 'N005', 'N008', 'N010', 'N011',\n",
    "           'N012', 'N016', 'P00104', 'P00404', 'P00901', 'P01001', 'P01101', 'P02001', 'P018', 'P019', 'P02002', 'P02501', 'P02602', 'P02601', 'P027', 'P02801', 'P029', 'P035', 'P03701', 'P03702',\n",
    "           'P04501', 'P04502', 'P050', 'P051', 'P053', 'P05401', 'P05404', 'P05407', 'P05410', 'P05413', 'P05416', 'P05419', 'P058', 'P06701', 'P068', 'Q00201', 'Q03001', 'Q060', 'Q06306', 'Q064',\n",
    "           'Q06506', 'Q06507', 'Q06508', 'Q06509', 'Q06601', 'Q067', 'Q068', 'Q11006', 'Q128', 'R034', 'R03601', 'R03607', 'R03608', 'R03610', 'S065', 'T001', 'H003', 'H004', 'H010']\n",
    "\n",
    "df = pd.read_csv(r'C:\\Users\\llays\\OneDrive\\Documentos\\GitHub\\DoencasCardiacas\\PNS2019\\pns2019.csv', usecols=colunas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c60cb62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Códigos dos estados do Nordeste\n",
    "nordeste = [21, 22, 23, 24, 25, 26, 27, 28, 29]\n",
    "\n",
    "# Códigos dos estados do Centro-Oeste\n",
    "centro_oeste = [50, 51, 52, 53]\n",
    "\n",
    "df_filtrado = df.dropna(subset=['Q06306'])\n",
    "\n",
    "df_filtrado = df_filtrado[\n",
    "    (df_filtrado['V0015'] == 1) & #Tipo da entrevista: Realizada (1)\n",
    "    (df_filtrado['V0001'].isin(nordeste + centro_oeste)) & #Região nordeste e centro-oeste apenas\n",
    "    (~df_filtrado['C012'].isin([3, 9])) & #Informante do Módulo C \n",
    "    (~df_filtrado['D015'].isin([3, 9])) & #Informante do Módulo D \n",
    "    (~df_filtrado['E027'].isin([3, 9])) & #Informante do Módulo E \n",
    "    (~df_filtrado['F016'].isin([3, 9])) & #Informante do Módulo F \n",
    "    (~df_filtrado['G032'].isin([3, 9])) & #Informante do Módulo G \n",
    "    (~df_filtrado['I012'].isin([3, 9])) & #Informante do Módulo I \n",
    "    (~df_filtrado['J060'].isin([3, 9])) & #Informante do Módulo J \n",
    "    (df_filtrado['M001'] == 1) & #Entrevista do adulto selecionado: Realizada (1)\n",
    "    (~df_filtrado['M00302'].isin([2])) & #O informante desta parte é: (todas as opções menos \"Não morador\")\n",
    "    (df_filtrado['Q064'] >= 40)  # Pessoas com 40 anos ou mais\n",
    "]\n",
    "\n",
    "colunas_existentes = [col for col in colunas if col in df_filtrado.columns]\n",
    "\n",
    "df_filtrado = df_filtrado[colunas_existentes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb7fde0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtrado.to_csv('base_doencas_cardiacas.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "750af834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V0001</th>\n",
       "      <th>V0015</th>\n",
       "      <th>V0026</th>\n",
       "      <th>V0031</th>\n",
       "      <th>B001</th>\n",
       "      <th>C006</th>\n",
       "      <th>C00701</th>\n",
       "      <th>C00702</th>\n",
       "      <th>C00703</th>\n",
       "      <th>C009</th>\n",
       "      <th>...</th>\n",
       "      <th>R034</th>\n",
       "      <th>R03601</th>\n",
       "      <th>R03607</th>\n",
       "      <th>R03608</th>\n",
       "      <th>R03610</th>\n",
       "      <th>S065</th>\n",
       "      <th>T001</th>\n",
       "      <th>H003</th>\n",
       "      <th>H004</th>\n",
       "      <th>H010</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65224</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65294</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1953.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65347</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65419</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1947.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65513</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293353</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1974.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293491</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1951.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293498</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293510</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1953.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293621</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1963.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1360 rows × 119 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        V0001  V0015  V0026  V0031  B001  C006  C00701  C00702  C00703  C009  \\\n",
       "65224      21      1      1      1   2.0   2.0     6.0     5.0  1970.0   4.0   \n",
       "65294      21      1      1      1   2.0   1.0    11.0     6.0  1953.0   5.0   \n",
       "65347      21      1      1      1   1.0   1.0    23.0     8.0  1946.0   1.0   \n",
       "65419      21      1      1      1   2.0   1.0    30.0     6.0  1947.0   1.0   \n",
       "65513      21      1      1      1   1.0   2.0     3.0     9.0  1946.0   2.0   \n",
       "...       ...    ...    ...    ...   ...   ...     ...     ...     ...   ...   \n",
       "293353     53      1      2      1   3.0   2.0     5.0     6.0  1974.0   1.0   \n",
       "293491     53      1      2      1   1.0   1.0    27.0     6.0  1951.0   1.0   \n",
       "293498     53      1      2      1   1.0   1.0    21.0     4.0  1946.0   2.0   \n",
       "293510     53      1      2      1   1.0   1.0    14.0    10.0  1953.0   4.0   \n",
       "293621     53      1      2      1   1.0   1.0    10.0    12.0  1963.0   4.0   \n",
       "\n",
       "        ...  R034  R03601  R03607  R03608  R03610  S065  T001  H003  H004  \\\n",
       "65224   ...   NaN     NaN     NaN     NaN     NaN   1.0   2.0   2.0   8.0   \n",
       "65294   ...   NaN     NaN     NaN     NaN     NaN   NaN   2.0   7.0   8.0   \n",
       "65347   ...   NaN     NaN     NaN     NaN     NaN   NaN   2.0   4.0   8.0   \n",
       "65419   ...   NaN     NaN     NaN     NaN     NaN   NaN   2.0   NaN   NaN   \n",
       "65513   ...   NaN     NaN     NaN     NaN     NaN   1.0   2.0   7.0   2.0   \n",
       "...     ...   ...     ...     ...     ...     ...   ...   ...   ...   ...   \n",
       "293353  ...   NaN     NaN     NaN     NaN     NaN   1.0   2.0   4.0   7.0   \n",
       "293491  ...   NaN     NaN     NaN     NaN     NaN   NaN   2.0   7.0   2.0   \n",
       "293498  ...   NaN     NaN     NaN     NaN     NaN   NaN   2.0   2.0   1.0   \n",
       "293510  ...   NaN     NaN     NaN     NaN     NaN   NaN   2.0   NaN   NaN   \n",
       "293621  ...   NaN     NaN     NaN     NaN     NaN   NaN   2.0   2.0   1.0   \n",
       "\n",
       "        H010  \n",
       "65224    NaN  \n",
       "65294    NaN  \n",
       "65347    NaN  \n",
       "65419    NaN  \n",
       "65513    NaN  \n",
       "...      ...  \n",
       "293353   NaN  \n",
       "293491   NaN  \n",
       "293498   1.0  \n",
       "293510   NaN  \n",
       "293621   1.0  \n",
       "\n",
       "[1360 rows x 119 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtrado[df_filtrado.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e29c41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['V0001', 'V0015', 'V0026', 'V0031', 'B001', 'C006', 'C009', 'C011', 'C012', 'D00901', 'D014', 'D015', 'E006011', \n",
    "               'E008', 'E010010', 'E027', 'F001011', 'F007011', 'F008011', 'VDF001', 'F016', 'G059', 'G060', 'G062', 'G032', \n",
    "               'I00102', 'I006', 'I004', 'I00401', 'I00402', 'I00403', 'I012', 'J001', 'J00101', 'J002', 'J00402', 'J00404', 'J007', \n",
    "               'J00801', 'J01101', 'J060', 'M001', 'M00302', 'M011011', 'M011021', 'M011051', 'M011071', 'N005', \n",
    "               'N008', 'N010', 'N011', 'N012', 'N016', 'P02601', 'P027', 'P050', 'P051', 'P06701', 'P068', 'Q00201', 'Q03001', 'Q060',\n",
    "               'Q06306', 'Q06506', 'Q06507', 'Q06508', 'Q06509', 'Q06601', 'Q067', 'Q068', 'Q11006', 'R034', 'R03601', 'R03607',\n",
    "               'R03608', 'R03610', 'S065', 'T001', 'H003', 'H004', 'H010']\n",
    "\n",
    "continuous = ['C00701', 'C00702', 'C00703', 'E01602', 'E01604', 'E017', 'E01802', 'E01804', 'E019', 'P00104',\n",
    "           'P00404', 'P00901', 'P01001', 'P01101', 'P02001', 'P018', 'P019', 'P02002', 'P02501', 'P02602',\n",
    "           'P02801', 'P029', 'P035', 'P03701', 'P03702', 'P04501', 'P04502', 'P053', 'P05401', 'P05404',\n",
    "           'P05407', 'P05410', 'P05413', 'P05416', 'P05419', 'P058', 'Q064']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186e43b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Plotando gráficos para colunas com dados faltantes:\n",
      "Gráfico salvo em: missing_data_plots\\D00901_missing_plot.png\n",
      "Gráfico salvo em: missing_data_plots\\D014_missing_plot.png\n",
      "Gráfico salvo em: missing_data_plots\\E006011_missing_plot.png\n",
      "Gráfico salvo em: missing_data_plots\\E008_missing_plot.png\n",
      "Gráfico salvo em: missing_data_plots\\E010010_missing_plot.png\n",
      "Gráfico salvo em: missing_data_plots\\E01602_missing_plot.png\n",
      "Gráfico salvo em: missing_data_plots\\E01604_missing_plot.png\n",
      "Gráfico salvo em: missing_data_plots\\E017_missing_plot.png\n",
      "Gráfico salvo em: missing_data_plots\\E01802_missing_plot.png\n",
      "Gráfico salvo em: missing_data_plots\\E01804_missing_plot.png\n",
      "Gráfico salvo em: missing_data_plots\\E019_missing_plot.png\n",
      "Gráfico salvo em: missing_data_plots\\G060_missing_plot.png\n",
      "Gráfico salvo em: missing_data_plots\\G062_missing_plot.png\n",
      "Gráfico salvo em: missing_data_plots\\I006_missing_plot.png\n",
      "Gráfico salvo em: missing_data_plots\\I004_missing_plot.png\n",
      "Gráfico salvo em: missing_data_plots\\I00401_missing_plot.png\n",
      "Gráfico salvo em: missing_data_plots\\I00402_missing_plot.png\n",
      "Gráfico salvo em: missing_data_plots\\I00403_missing_plot.png\n",
      "Gráfico salvo em: missing_data_plots\\J00402_missing_plot.png\n",
      "Gráfico salvo em: missing_data_plots\\J00404_missing_plot.png\n",
      "Gráfico salvo em: missing_data_plots\\M00302_missing_plot.png\n",
      "Gráfico salvo em: missing_data_plots\\M011011_missing_plot.png\n",
      "Gráfico salvo em: missing_data_plots\\M011021_missing_plot.png\n",
      "Gráfico salvo em: missing_data_plots\\M011051_missing_plot.png\n",
      "Gráfico salvo em: missing_data_plots\\M011071_missing_plot.png\n",
      "Gráfico salvo em: missing_data_plots\\N005_missing_plot.png\n",
      "Gráfico salvo em: missing_data_plots\\N008_missing_plot.png\n",
      "Gráfico salvo em: missing_data_plots\\P01001_missing_plot.png\n",
      "Gráfico salvo em: missing_data_plots\\P019_missing_plot.png\n",
      "Gráfico salvo em: missing_data_plots\\P02801_missing_plot.png\n",
      "Gráfico salvo em: missing_data_plots\\P029_missing_plot.png\n",
      "Gráfico salvo em: missing_data_plots\\P035_missing_plot.png\n",
      "Gráfico salvo em: missing_data_plots\\P03701_missing_plot.png\n",
      "Gráfico salvo em: missing_data_plots\\P03702_missing_plot.png\n",
      "Gráfico salvo em: missing_data_plots\\P051_missing_plot.png\n",
      "Gráfico salvo em: missing_data_plots\\P053_missing_plot.png\n",
      "Gráfico salvo em: missing_data_plots\\P05401_missing_plot.png\n",
      "Gráfico salvo em: missing_data_plots\\P05404_missing_plot.png\n",
      "Gráfico salvo em: missing_data_plots\\P05407_missing_plot.png\n",
      "Gráfico salvo em: missing_data_plots\\P05410_missing_plot.png\n",
      "Gráfico salvo em: missing_data_plots\\P05413_missing_plot.png\n",
      "Gráfico salvo em: missing_data_plots\\P05416_missing_plot.png\n",
      "Gráfico salvo em: missing_data_plots\\P05419_missing_plot.png\n",
      "Gráfico salvo em: missing_data_plots\\P058_missing_plot.png\n",
      "Gráfico salvo em: missing_data_plots\\Q00201_missing_plot.png\n",
      "Gráfico salvo em: missing_data_plots\\Q03001_missing_plot.png\n",
      "Gráfico salvo em: missing_data_plots\\Q060_missing_plot.png\n",
      "Gráfico salvo em: missing_data_plots\\R034_missing_plot.png\n",
      "Gráfico salvo em: missing_data_plots\\R03601_missing_plot.png\n",
      "Gráfico salvo em: missing_data_plots\\R03607_missing_plot.png\n",
      "Gráfico salvo em: missing_data_plots\\R03608_missing_plot.png\n",
      "Gráfico salvo em: missing_data_plots\\R03610_missing_plot.png\n",
      "Gráfico salvo em: missing_data_plots\\S065_missing_plot.png\n",
      "Gráfico salvo em: missing_data_plots\\H003_missing_plot.png\n",
      "Gráfico salvo em: missing_data_plots\\H004_missing_plot.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\llays\\AppData\\Local\\Temp\\ipykernel_31040\\2336988015.py:144: UserWarning: Glyph 148 (\\x94) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\llays\\AppData\\Local\\Temp\\ipykernel_31040\\2336988015.py:148: UserWarning: Glyph 148 (\\x94) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(save_path, dpi=300, bbox_inches='tight')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gráfico salvo em: missing_data_plots\\H010_missing_plot.png\n",
      "\n",
      "Análise concluída com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import rcParams\n",
    "import os\n",
    "\n",
    "# =============================================\n",
    "# CONFIGURAÇÕES INICIAIS\n",
    "# =============================================\n",
    "\n",
    "# Configurações de estilo melhoradas\n",
    "plt.style.use('ggplot')\n",
    "rcParams['font.family'] = 'DejaVu Sans'\n",
    "rcParams['figure.figsize'] = (12, 7)\n",
    "rcParams['axes.titlesize'] = 14\n",
    "rcParams['axes.labelsize'] = 12\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# =============================================\n",
    "# CARREGAMENTO E PREPARAÇÃO DOS DADOS\n",
    "# =============================================\n",
    "\n",
    "# Lista de colunas a serem carregadas\n",
    "colunas = ['V0001', 'V0015', 'V0026', 'V0031', 'B001', 'C006', 'C00701', 'C00702', 'C00703', \n",
    "           'C009', 'C011', 'C012', 'D00901', 'D014', 'D015', 'E006011', 'E008', 'E010010', \n",
    "           'E01602', 'E01604', 'E017', 'E01802', 'E01804', 'E019', 'E027', 'F001011', \n",
    "           'F007011', 'F008011', 'VDF001', 'F016', 'G059', 'G060', 'G062', 'G032', 'I00102', \n",
    "           'I006', 'I004', 'I00401', 'I00402', 'I00403', 'I012', 'J001', 'J00101', 'J002', \n",
    "           'J00402', 'J00404', 'J007', 'J00801', 'J01101', 'J060', 'M001', 'M00302', \n",
    "           'M011011', 'M011021', 'M011051', 'M011071', 'N005', 'N008', 'N010', 'N011',\n",
    "           'N012', 'N016', 'P00104', 'P00404', 'P00901', 'P01001', 'P01101', 'P02001', \n",
    "           'P018', 'P019', 'P02002', 'P02501', 'P02602', 'P02601', 'P027', 'P02801', \n",
    "           'P029', 'P035', 'P03701', 'P03702', 'P04501', 'P04502', 'P050', 'P051', 'P053', \n",
    "           'P05401', 'P05404', 'P05407', 'P05410', 'P05413', 'P05416', 'P05419', 'P058', \n",
    "           'P06701', 'P068', 'Q00201', 'Q03001', 'Q060', 'Q06306', 'Q064', 'Q06506', \n",
    "           'Q06507', 'Q06508', 'Q06509', 'Q06601', 'Q067', 'Q068', 'Q11006', 'Q128', \n",
    "           'R034', 'R03601', 'R03607', 'R03608', 'R03610', 'S065', 'T001', 'H003', 'H004', 'H010']\n",
    "\n",
    "# Carregar dados principais\n",
    "try:\n",
    "    df = pd.read_csv(r'C:\\Users\\llays\\OneDrive\\Documentos\\GitHub\\DoencasCardiacas\\PNS2019\\pns2019.csv', \n",
    "                    usecols=colunas, \n",
    "                    encoding='latin1')\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao ler o arquivo de dados: {str(e)}\")\n",
    "    exit()\n",
    "\n",
    "# Carregar mapeamento de códigos para nomes\n",
    "try:\n",
    "    nomes_colunas = pd.read_csv(r'C:\\Users\\llays\\OneDrive\\Documentos\\GitHub\\DoencasCardiacas\\PNS2019\\PNS_titulos.csv', \n",
    "                              sep=';', \n",
    "                              encoding='latin1')\n",
    "    nome_por_codigo = dict(zip(nomes_colunas.iloc[:, 0], nomes_colunas.iloc[:, 1]))\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao ler o arquivo de mapeamento: {str(e)}\")\n",
    "    exit()\n",
    "\n",
    "# =============================================\n",
    "# FILTRAGEM DOS DADOS\n",
    "# =============================================\n",
    "\n",
    "# Códigos das regiões\n",
    "nordeste = [21, 22, 23, 24, 25, 26, 27, 28, 29]\n",
    "centro_oeste = [50, 51, 52, 53]\n",
    "\n",
    "# Aplicar filtros\n",
    "df_filtrado = df.dropna(subset=['Q06306'])\n",
    "\n",
    "df_filtrado = df_filtrado[\n",
    "    (df_filtrado['V0015'] == 1) & # Tipo da entrevista: Realizada (1)\n",
    "    (df_filtrado['V0001'].isin(nordeste + centro_oeste)) & # Região nordeste e centro-oeste\n",
    "    (~df_filtrado['C012'].isin([3, 9])) & # Informante do Módulo C válido\n",
    "    (~df_filtrado['D015'].isin([3, 9])) & # Informante do Módulo D válido\n",
    "    (~df_filtrado['E027'].isin([3, 9])) & # Informante do Módulo E válido\n",
    "    (~df_filtrado['F016'].isin([3, 9])) & # Informante do Módulo F válido\n",
    "    (~df_filtrado['G032'].isin([3, 9])) & # Informante do Módulo G válido\n",
    "    (~df_filtrado['I012'].isin([3, 9])) & # Informante do Módulo I válido\n",
    "    (~df_filtrado['J060'].isin([3, 9])) & # Informante do Módulo J válido\n",
    "    (df_filtrado['M001'] == 1) & # Entrevista do adulto selecionado: Realizada (1)\n",
    "    (~df_filtrado['M00302'].isin([2])) & # Informante é morador\n",
    "    (df_filtrado['Q064'] >= 40)  # Pessoas com 40 anos ou mais\n",
    "]\n",
    "\n",
    "# Selecionar apenas colunas existentes\n",
    "colunas_existentes = [col for col in colunas if col in df_filtrado.columns]\n",
    "df_filtrado = df_filtrado[colunas_existentes]\n",
    "\n",
    "# =============================================\n",
    "# IDENTIFICAÇÃO DE DADOS FALTANTES\n",
    "# =============================================\n",
    "\n",
    "# Identificar colunas com dados faltantes\n",
    "colunas_com_faltantes = df_filtrado.columns[df_filtrado.isnull().any()].tolist()\n",
    "\n",
    "# Verificar se há colunas com dados faltantes\n",
    "if not colunas_com_faltantes:\n",
    "    print(\"Nenhuma coluna com dados faltantes encontrada.\")\n",
    "    exit()\n",
    "\n",
    "# =============================================\n",
    "# FUNÇÃO PARA PLOTAGEM DOS GRÁFICOS DE DADOS FALTANTES\n",
    "# =============================================\n",
    "\n",
    "def plot_missing_data(df, columns_with_missing, nome_por_codigo, save_dir='missing_data_plots'):\n",
    "    \"\"\"\n",
    "    Função para plotar gráficos de dados faltantes\n",
    "    \n",
    "    Parâmetros:\n",
    "    - df: DataFrame com os dados\n",
    "    - columns_with_missing: lista de colunas com dados faltantes\n",
    "    - nome_por_codigo: dicionário de mapeamento código -> nome\n",
    "    - save_dir: diretório para salvar os gráficos\n",
    "    \"\"\"\n",
    "    \n",
    "    # Criar diretório para salvar os gráficos\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    for col in columns_with_missing:\n",
    "        try:\n",
    "            # Obter nome descritivo\n",
    "            nome_desc = nome_por_codigo.get(col, '')\n",
    "            titulo = f\"{col} - {nome_desc}\" if nome_desc else col\n",
    "            \n",
    "            plt.figure()\n",
    "            \n",
    "            # Criar série booleana indicando valores faltantes\n",
    "            missing = df[col].isna()\n",
    "            \n",
    "            # Contar valores faltantes e não faltantes\n",
    "            counts = missing.value_counts()\n",
    "            \n",
    "            # Plotar gráfico de barras\n",
    "            counts.plot(kind='bar', rot=0)\n",
    "            plt.title(f'Dados Faltantes em {titulo}', pad=15)\n",
    "            plt.xlabel('Valor Faltante')\n",
    "            plt.ylabel('Contagem')\n",
    "            plt.xticks([0, 1], ['Presente', 'Faltante'])\n",
    "            \n",
    "            # Adicionar os valores nas barras\n",
    "            for i, v in enumerate(counts):\n",
    "                plt.text(i, v + 0.02 * max(counts), str(v), ha='center')\n",
    "            \n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Salvar o gráfico\n",
    "            save_path = os.path.join(save_dir, f\"{col}_missing_plot.png\")\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "            plt.close()  # Fechar a figura para liberar memória\n",
    "            print(f\"Gráfico salvo em: {save_path}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"ERRO ao plotar {col}: {str(e)}\")\n",
    "\n",
    "# =============================================\n",
    "# EXECUÇÃO DA ANÁLISE\n",
    "# =============================================\n",
    "\n",
    "print(\"\\nPlotando gráficos para colunas com dados faltantes:\")\n",
    "plot_missing_data(df_filtrado, colunas_com_faltantes, nome_por_codigo)\n",
    "\n",
    "print(\"\\nAnálise concluída com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "203d3013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ANÁLISE COMPLETA DE DADOS FALTANTES\n",
      "======================================================================\n",
      "\n",
      "COLUNAS SEM DADOS FALTANTES (63/119):\n",
      "--------------------------------------------------\n",
      "1. V0001\n",
      "2. V0015\n",
      "3. V0026\n",
      "4. V0031\n",
      "5. B001\n",
      "6. C006\n",
      "7. C00701\n",
      "8. C00702\n",
      "9. C00703\n",
      "10. C009\n",
      "11. C011\n",
      "12. C012\n",
      "13. D015\n",
      "14. E027\n",
      "15. F001011\n",
      "16. F007011\n",
      "17. F008011\n",
      "18. VDF001\n",
      "19. F016\n",
      "20. G059\n",
      "21. G032\n",
      "22. I00102\n",
      "23. I012\n",
      "24. J001\n",
      "25. J00101\n",
      "26. J002\n",
      "27. J007\n",
      "28. J00801\n",
      "29. J01101\n",
      "30. J060\n",
      "31. M001\n",
      "32. N010\n",
      "33. N011\n",
      "34. N012\n",
      "35. N016\n",
      "36. P00104\n",
      "37. P00404\n",
      "38. P00901\n",
      "39. P01101\n",
      "40. P02001\n",
      "41. P018\n",
      "42. P02002\n",
      "43. P02501\n",
      "44. P02602\n",
      "45. P02601\n",
      "46. P027\n",
      "47. P04501\n",
      "48. P04502\n",
      "49. P050\n",
      "50. P06701\n",
      "51. P068\n",
      "52. Q06306\n",
      "53. Q064\n",
      "54. Q06506\n",
      "55. Q06507\n",
      "56. Q06508\n",
      "57. Q06509\n",
      "58. Q06601\n",
      "59. Q067\n",
      "60. Q068\n",
      "61. Q11006\n",
      "62. Q128\n",
      "63. T001\n",
      "\n",
      "COLUNAS COM DADOS FALTANTES (56/119):\n",
      "--------------------------------------------------\n",
      "Coluna           Faltantes     % Faltantes\n",
      "--------------------------------------------------\n",
      "D00901                 222          16.32%\n",
      "D014                   284          20.88%\n",
      "E006011              1,341          98.60%\n",
      "E008                 1,348          99.12%\n",
      "E010010              1,355          99.63%\n",
      "E01602                 965          70.96%\n",
      "E01604               1,355          99.63%\n",
      "E017                   959          70.51%\n",
      "E01802               1,332          97.94%\n",
      "E01804               1,360         100.00%\n",
      "E019                 1,332          97.94%\n",
      "G060                 1,241          91.25%\n",
      "G062                 1,241          91.25%\n",
      "I006                 1,029          75.66%\n",
      "I004                 1,097          80.66%\n",
      "I00401               1,097          80.66%\n",
      "I00402               1,097          80.66%\n",
      "I00403               1,097          80.66%\n",
      "J00402               1,065          78.31%\n",
      "J00404               1,065          78.31%\n",
      "M00302               1,303          95.81%\n",
      "M011011                959          70.51%\n",
      "M011021                959          70.51%\n",
      "M011051                959          70.51%\n",
      "M011071                959          70.51%\n",
      "N005                   119           8.75%\n",
      "N008                   844          62.06%\n",
      "P01001                 634          46.62%\n",
      "P019                   593          43.60%\n",
      "P02801               1,187          87.28%\n",
      "P029                 1,085          79.78%\n",
      "P035                   939          69.04%\n",
      "P03701                 949          69.78%\n",
      "P03702                 949          69.78%\n",
      "P051                 1,353          99.49%\n",
      "P053                   679          49.93%\n",
      "P05401               1,234          90.74%\n",
      "P05404               1,234          90.74%\n",
      "P05407               1,234          90.74%\n",
      "P05410               1,234          90.74%\n",
      "P05413               1,234          90.74%\n",
      "P05416               1,234          90.74%\n",
      "P05419               1,234          90.74%\n",
      "P058                   742          54.56%\n",
      "Q00201                   1           0.07%\n",
      "Q03001                  10           0.74%\n",
      "Q060                    16           1.18%\n",
      "R034                 1,319          96.99%\n",
      "R03601               1,345          98.90%\n",
      "R03607               1,345          98.90%\n",
      "R03608               1,345          98.90%\n",
      "R03610               1,345          98.90%\n",
      "S065                   583          42.87%\n",
      "H003                   656          48.24%\n",
      "H004                   656          48.24%\n",
      "H010                 1,141          83.90%\n",
      "\n",
      "RESUMO ESTATÍSTICO:\n",
      "--------------------------------------------------\n",
      "Total de colunas analisadas: 119\n",
      "Colunas sem dados faltantes: 63\n",
      "Colunas com dados faltantes: 56\n",
      "Total de valores faltantes: 55,494\n",
      "Percentual de dados faltantes: 34.29%\n",
      "\n",
      "Relatório completo salvo em 'relatorio_dados_faltantes.txt'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carregar os dados (substitua pelo seu caminho real)\n",
    "try:\n",
    "    df = pd.read_csv(r'C:\\Users\\llays\\OneDrive\\Documentos\\GitHub\\DoencasCardiacas\\PNS2019\\base_doencas_cardiacas.csv', \n",
    "                    encoding='latin1')\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao ler o arquivo de dados: {str(e)}\")\n",
    "    exit()\n",
    "\n",
    "# Análise de dados faltantes\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ANÁLISE COMPLETA DE DADOS FALTANTES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 1. Colunas SEM dados faltantes\n",
    "colunas_sem_faltantes = df.columns[~df.isnull().any()].tolist()\n",
    "print(f\"\\nCOLUNAS SEM DADOS FALTANTES ({len(colunas_sem_faltantes)}/{len(df.columns)}):\")\n",
    "print(\"-\"*50)\n",
    "for i, coluna in enumerate(colunas_sem_faltantes, 1):\n",
    "    print(f\"{i}. {coluna}\")\n",
    "\n",
    "# 2. Colunas COM dados faltantes\n",
    "dados_faltantes = df.isnull().sum()\n",
    "colunas_com_faltantes = dados_faltantes[dados_faltantes > 0]\n",
    "\n",
    "print(f\"\\nCOLUNAS COM DADOS FALTANTES ({len(colunas_com_faltantes)}/{len(df.columns)}):\")\n",
    "print(\"-\"*50)\n",
    "print(f\"{'Coluna':<15} {'Faltantes':>10} {'% Faltantes':>15}\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "for coluna, qtd in colunas_com_faltantes.items():\n",
    "    percentual = (qtd / len(df)) * 100\n",
    "    print(f\"{coluna:<15} {qtd:>10,} {percentual:>14.2f}%\")\n",
    "\n",
    "# 3. Resumo estatístico\n",
    "total_faltantes = dados_faltantes.sum()\n",
    "percentual_total = (total_faltantes / (len(df) * len(df.columns))) * 100\n",
    "\n",
    "print(\"\\nRESUMO ESTATÍSTICO:\")\n",
    "print(\"-\"*50)\n",
    "print(f\"Total de colunas analisadas: {len(df.columns)}\")\n",
    "print(f\"Colunas sem dados faltantes: {len(colunas_sem_faltantes)}\")\n",
    "print(f\"Colunas com dados faltantes: {len(colunas_com_faltantes)}\")\n",
    "print(f\"Total de valores faltantes: {total_faltantes:,}\")\n",
    "print(f\"Percentual de dados faltantes: {percentual_total:.2f}%\")\n",
    "\n",
    "# Salvar relatório completo\n",
    "with open('relatorio_dados_faltantes.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(\"RELATÓRIO COMPLETO DE DADOS FALTANTES\\n\")\n",
    "    f.write(\"=\"*70 + \"\\n\\n\")\n",
    "    \n",
    "    f.write(f\"COLUNAS SEM DADOS FALTANTES ({len(colunas_sem_faltantes)}/{len(df.columns)}):\\n\")\n",
    "    f.write(\"-\"*50 + \"\\n\")\n",
    "    for coluna in colunas_sem_faltantes:\n",
    "        f.write(f\"{coluna}\\n\")\n",
    "    \n",
    "    f.write(\"\\n\\nCOLUNAS COM DADOS FALTANTES:\\n\")\n",
    "    f.write(\"-\"*50 + \"\\n\")\n",
    "    f.write(f\"{'Coluna':<15} {'Faltantes':>10} {'% Faltantes':>15}\\n\")\n",
    "    f.write(\"-\"*50 + \"\\n\")\n",
    "    for coluna, qtd in colunas_com_faltantes.items():\n",
    "        percentual = (qtd / len(df)) * 100\n",
    "        f.write(f\"{coluna:<15} {qtd:>10,} {percentual:>14.2f}%\\n\")\n",
    "    \n",
    "    f.write(\"\\nRESUMO ESTATÍSTICO:\\n\")\n",
    "    f.write(\"-\"*50 + \"\\n\")\n",
    "    f.write(f\"Total de colunas analisadas: {len(df.columns)}\\n\")\n",
    "    f.write(f\"Colunas sem dados faltantes: {len(colunas_sem_faltantes)}\\n\")\n",
    "    f.write(f\"Colunas com dados faltantes: {len(colunas_com_faltantes)}\\n\")\n",
    "    f.write(f\"Total de valores faltantes: {total_faltantes:,}\\n\")\n",
    "    f.write(f\"Percentual de dados faltantes: {percentual_total:.2f}%\\n\")\n",
    "\n",
    "print(\"\\nRelatório completo salvo em 'relatorio_dados_faltantes.txt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "afc511f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Plotando gráficos de proporção de dados faltantes:\n",
      "Gráfico salvo em: stacked_missing_plots\\stacked_missing_plot_1_of_5.png\n",
      "Gráfico salvo em: stacked_missing_plots\\stacked_missing_plot_2_of_5.png\n",
      "Gráfico salvo em: stacked_missing_plots\\stacked_missing_plot_3_of_5.png\n",
      "Gráfico salvo em: stacked_missing_plots\\stacked_missing_plot_4_of_5.png\n",
      "Gráfico salvo em: stacked_missing_plots\\stacked_missing_plot_5_of_5.png\n",
      "\n",
      "Análise concluída com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import rcParams\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# =============================================\n",
    "# CONFIGURAÇÕES INICIAIS\n",
    "# =============================================\n",
    "\n",
    "# Configurações de estilo melhoradas\n",
    "plt.style.use('ggplot')\n",
    "rcParams['font.family'] = 'DejaVu Sans'\n",
    "rcParams['figure.figsize'] = (15, 10)\n",
    "rcParams['axes.titlesize'] = 16\n",
    "rcParams['axes.labelsize'] = 14\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# =============================================\n",
    "# CARREGAMENTO E PREPARAÇÃO DOS DADOS\n",
    "# =============================================\n",
    "\n",
    "# Lista de colunas a serem carregadas\n",
    "colunas = ['V0001', 'V0015', 'V0026', 'V0031', 'B001', 'C006', 'C00701', 'C00702', 'C00703', \n",
    "           'C009', 'C011', 'C012', 'D00901', 'D014', 'D015', 'E006011', 'E008', 'E010010', \n",
    "           'E01602', 'E01604', 'E017', 'E01802', 'E01804', 'E019', 'E027', 'F001011', \n",
    "           'F007011', 'F008011', 'VDF001', 'F016', 'G059', 'G060', 'G062', 'G032', 'I00102', \n",
    "           'I006', 'I004', 'I00401', 'I00402', 'I00403', 'I012', 'J001', 'J00101', 'J002', \n",
    "           'J00402', 'J00404', 'J007', 'J00801', 'J01101', 'J060', 'M001', 'M00302', \n",
    "           'M011011', 'M011021', 'M011051', 'M011071', 'N005', 'N008', 'N010', 'N011',\n",
    "           'N012', 'N016', 'P00104', 'P00404', 'P00901', 'P01001', 'P01101', 'P02001', \n",
    "           'P018', 'P019', 'P02002', 'P02501', 'P02602', 'P02601', 'P027', 'P02801', \n",
    "           'P029', 'P035', 'P03701', 'P03702', 'P04501', 'P04502', 'P050', 'P051', 'P053', \n",
    "           'P05401', 'P05404', 'P05407', 'P05410', 'P05413', 'P05416', 'P05419', 'P058', \n",
    "           'P06701', 'P068', 'Q00201', 'Q03001', 'Q060', 'Q06306', 'Q064', 'Q06506', \n",
    "           'Q06507', 'Q06508', 'Q06509', 'Q06601', 'Q067', 'Q068', 'Q11006', 'Q128', \n",
    "           'R034', 'R03601', 'R03607', 'R03608', 'R03610', 'S065', 'T001', 'H003', 'H004', 'H010']\n",
    "\n",
    "# Carregar dados principais\n",
    "try:\n",
    "    df = pd.read_csv(r'C:\\Users\\llays\\OneDrive\\Documentos\\GitHub\\DoencasCardiacas\\PNS2019\\base_doencas_cardiacas.csv', \n",
    "                    usecols=colunas, \n",
    "                    encoding='latin1')\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao ler o arquivo de dados: {str(e)}\")\n",
    "    exit()\n",
    "\n",
    "# Carregar mapeamento de códigos para nomes\n",
    "try:\n",
    "    nomes_colunas = pd.read_csv(r'C:\\Users\\llays\\OneDrive\\Documentos\\GitHub\\DoencasCardiacas\\PNS2019\\PNS_titulos.csv', \n",
    "                              sep=';', \n",
    "                              encoding='latin1')\n",
    "    nome_por_codigo = dict(zip(nomes_colunas.iloc[:, 0], nomes_colunas.iloc[:, 1]))\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao ler o arquivo de mapeamento: {str(e)}\")\n",
    "    exit()\n",
    "\n",
    "# =============================================\n",
    "# FILTRAGEM DOS DADOS\n",
    "# =============================================\n",
    "\n",
    "# Códigos das regiões\n",
    "nordeste = [21, 22, 23, 24, 25, 26, 27, 28, 29]\n",
    "centro_oeste = [50, 51, 52, 53]\n",
    "\n",
    "# Aplicar filtros\n",
    "df_filtrado = df.dropna(subset=['Q06306'])\n",
    "\n",
    "df_filtrado = df_filtrado[\n",
    "    (df_filtrado['V0015'] == 1) & # Tipo da entrevista: Realizada (1)\n",
    "    (df_filtrado['V0001'].isin(nordeste + centro_oeste)) & # Região nordeste e centro-oeste\n",
    "    (~df_filtrado['C012'].isin([3, 9])) & # Informante do Módulo C válido\n",
    "    (~df_filtrado['D015'].isin([3, 9])) & # Informante do Módulo D válido\n",
    "    (~df_filtrado['E027'].isin([3, 9])) & # Informante do Módulo E válido\n",
    "    (~df_filtrado['F016'].isin([3, 9])) & # Informante do Módulo F válido\n",
    "    (~df_filtrado['G032'].isin([3, 9])) & # Informante do Módulo G válido\n",
    "    (~df_filtrado['I012'].isin([3, 9])) & # Informante do Módulo I válido\n",
    "    (~df_filtrado['J060'].isin([3, 9])) & # Informante do Módulo J válido\n",
    "    (df_filtrado['M001'] == 1) & # Entrevista do adulto selecionado: Realizada (1)\n",
    "    (~df_filtrado['M00302'].isin([2])) & # Informante é morador\n",
    "    (df_filtrado['Q064'] >= 40)  # Pessoas com 40 anos ou mais\n",
    "]\n",
    "\n",
    "# Selecionar apenas colunas existentes\n",
    "colunas_existentes = [col for col in colunas if col in df_filtrado.columns]\n",
    "df_filtrado = df_filtrado[colunas_existentes]\n",
    "\n",
    "# =============================================\n",
    "# IDENTIFICAÇÃO DE DADOS FALTANTES\n",
    "# =============================================\n",
    "\n",
    "# Identificar colunas com dados faltantes\n",
    "colunas_com_faltantes = df_filtrado.columns[df_filtrado.isnull().any()].tolist()\n",
    "\n",
    "if not colunas_com_faltantes:\n",
    "    print(\"Nenhuma coluna com dados faltantes encontrada.\")\n",
    "    exit()\n",
    "\n",
    "# Ordenar colunas por quantidade de dados faltantes (decrescente)\n",
    "colunas_com_faltantes = sorted(colunas_com_faltantes, \n",
    "                              key=lambda x: df_filtrado[x].isna().sum(), \n",
    "                              reverse=True)\n",
    "\n",
    "# =============================================\n",
    "# FUNÇÃO PARA GRÁFICOS RELATIVOS (100% STACKED)\n",
    "# =============================================\n",
    "\n",
    "def plot_stacked_missing_data(df, columns_with_missing, nome_por_codigo, save_dir='stacked_missing_plots'):\n",
    "    \"\"\"\n",
    "    Função para plotar gráficos de barras empilhadas (100%) mostrando a proporção de dados faltantes\n",
    "    \n",
    "    Parâmetros:\n",
    "    - df: DataFrame com os dados\n",
    "    - columns_with_missing: lista de colunas com dados faltantes\n",
    "    - nome_por_codigo: dicionário de mapeamento código -> nome\n",
    "    - save_dir: diretório para salvar os gráficos\n",
    "    \"\"\"\n",
    "    \n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # Dividir em 5 gráficos\n",
    "    num_grupos = 5\n",
    "    grupos = np.array_split(columns_with_missing, num_grupos)\n",
    "    \n",
    "    for i, grupo in enumerate(grupos, 1):\n",
    "        plt.figure(figsize=(18, 12))\n",
    "        \n",
    "        # Preparar dados\n",
    "        present = []\n",
    "        missing = []\n",
    "        labels = []\n",
    "        \n",
    "        for col in grupo:\n",
    "            nome_desc = nome_por_codigo.get(col, col)\n",
    "            labels.append(f\"{col}\\n{nome_desc[:25] + '...' if len(nome_desc) > 25 else nome_desc}\")\n",
    "            \n",
    "            total = len(df[col])\n",
    "            miss = df[col].isna().sum()\n",
    "            pres = total - miss\n",
    "            \n",
    "            present.append(pres)\n",
    "            missing.append(miss)\n",
    "        \n",
    "        # Converter para porcentagens\n",
    "        total = np.array(present) + np.array(missing)\n",
    "        present_pct = np.array(present) / total * 100\n",
    "        missing_pct = np.array(missing) / total * 100\n",
    "        \n",
    "        # Plotar\n",
    "        bars_present = plt.barh(labels, present_pct, color='#2ecc71', label='Presente')\n",
    "        bars_missing = plt.barh(labels, missing_pct, left=present_pct, color='#e74c3c', label='Faltante')\n",
    "        \n",
    "        # Adicionar valores\n",
    "        for bar_p, bar_m, val_p, val_m, pct_p, pct_m in zip(bars_present, bars_missing, present, missing, present_pct, missing_pct):\n",
    "            if pct_p > 5:\n",
    "                plt.text(bar_p.get_width()/2, bar_p.get_y() + bar_p.get_height()/2, \n",
    "                        f'{val_p:,}\\n({pct_p:.1f}%)', \n",
    "                        ha='center', va='center', color='white', fontsize=10, fontweight='bold')\n",
    "            \n",
    "            if pct_m > 5:\n",
    "                plt.text(bar_p.get_width() + bar_m.get_width()/2, bar_m.get_y() + bar_m.get_height()/2, \n",
    "                        f'{val_m:,}\\n({pct_m:.1f}%)', \n",
    "                        ha='center', va='center', color='white', fontsize=10, fontweight='bold')\n",
    "        \n",
    "        # Configurações\n",
    "        plt.title(f'Proporção de Dados Faltantes - Gráfico {i} de {len(grupos)}\\n(Total de registros: {len(df):,})', \n",
    "                 pad=20, fontsize=16)\n",
    "        plt.xlabel('Porcentagem (%)', fontsize=14)\n",
    "        plt.xlim(0, 100)\n",
    "        plt.grid(True, axis='x', alpha=0.3)\n",
    "        plt.legend(loc='lower center', bbox_to_anchor=(0.5, -0.12), ncol=2, fontsize=12)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Salvar\n",
    "        save_path = os.path.join(save_dir, f'stacked_missing_plot_{i}_of_{len(grupos)}.png')\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"Gráfico salvo em: {save_path}\")\n",
    "\n",
    "# =============================================\n",
    "# EXECUÇÃO DA ANÁLISE\n",
    "# =============================================\n",
    "\n",
    "print(\"\\nPlotando gráficos de proporção de dados faltantes:\")\n",
    "plot_stacked_missing_data(df_filtrado, colunas_com_faltantes, nome_por_codigo)\n",
    "\n",
    "print(\"\\nAnálise concluída com sucesso!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
